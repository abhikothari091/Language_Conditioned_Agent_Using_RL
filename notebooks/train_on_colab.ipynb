{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# ðŸ¤– Language-Conditioned RL Agent Training\n",
                "\n",
                "## Setup\n",
                "1. **Runtime** â†’ **Change runtime type** â†’ **T4 GPU**\n",
                "2. Run all cells in order\n",
                "3. Download trained model at the end\n",
                "\n",
                "**Time**: ~45-90 minutes for 200 iterations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "!pip install minigrid gymnasium numpy torch tqdm matplotlib -q\n",
                "!pip install 'ray[rllib]' -q\n",
                "print(\"âœ… Dependencies installed!\")\n",
                "print(\"âœ… Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "create_env"
            },
            "outputs": [],
            "source": [
                "# Create environment module file (REQUIRED for workers)\n",
                "import os\n",
                "os.makedirs('minigrid_env', exist_ok=True)\n",
                "\n",
                "env_code = '''\n",
                "import gymnasium as gym\n",
                "from gymnasium import spaces\n",
                "import numpy as np\n",
                "import minigrid\n",
                "\n",
                "class MiniGridFlatEnv(gym.Env):\n",
                "    def __init__(self, config=None):\n",
                "        super().__init__()\n",
                "        config = config or {}\n",
                "        env_name = config.get(\"env_name\", \"BabyAI-GoToObj-v0\")\n",
                "        max_steps = config.get(\"max_steps\", 64)\n",
                "        self.env = gym.make(env_name, render_mode=\"rgb_array\")\n",
                "        self.env.unwrapped.max_steps = max_steps\n",
                "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(151,), dtype=np.float32)\n",
                "        self.action_space = self.env.action_space\n",
                "        self.instruction = \"\"\n",
                "    \n",
                "    def _flatten_obs(self, obs):\n",
                "        image = obs[\"image\"].flatten().astype(np.float32) / 10.0\n",
                "        direction = np.zeros(4, dtype=np.float32)\n",
                "        direction[obs[\"direction\"]] = 1.0\n",
                "        return np.concatenate([image, direction])\n",
                "    \n",
                "    def reset(self, *, seed=None, options=None):\n",
                "        obs, info = self.env.reset(seed=seed, options=options)\n",
                "        self.instruction = self.env.unwrapped.mission\n",
                "        return self._flatten_obs(obs), info\n",
                "    \n",
                "    def step(self, action):\n",
                "        obs, reward, term, trunc, info = self.env.step(action)\n",
                "        return self._flatten_obs(obs), reward, term, trunc, info\n",
                "'''\n",
                "\n",
                "with open('minigrid_env/__init__.py', 'w') as f:\n",
                "    f.write('from minigrid_env.flat_env import MiniGridFlatEnv\\n')\n",
                "with open('minigrid_env/flat_env.py', 'w') as f:\n",
                "    f.write(env_code)\n",
                "print(\"âœ… Environment module created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "verify_env"
            },
            "outputs": [],
            "source": [
                "# Verify environment\n",
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "from minigrid_env import MiniGridFlatEnv\n",
                "\n",
                "env = MiniGridFlatEnv({\"env_name\": \"BabyAI-GoToObj-v0\"})\n",
                "obs, _ = env.reset(seed=42)\n",
                "print(f\"Obs shape: {obs.shape}, Instruction: {env.instruction}\")\n",
                "print(\"âœ… Environment works!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ray_init"
            },
            "outputs": [],
            "source": [
                "import ray\n",
                "from ray.rllib.algorithms.ppo import PPOConfig\n",
                "from ray.tune.registry import register_env\n",
                "import torch\n",
                "\n",
                "if ray.is_initialized():\n",
                "    ray.shutdown()\n",
                "ray.init(ignore_reinit_error=True)\n",
                "\n",
                "def env_creator(config):\n",
                "    from minigrid_env import MiniGridFlatEnv\n",
                "    return MiniGridFlatEnv(config)\n",
                "\n",
                "register_env(\"MiniGridFlat-v0\", env_creator)\n",
                "\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "print(\"âœ… Ray initialized!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "# PPO Config - OLD API for stability\n",
                "config = (\n",
                "    PPOConfig()\n",
                "    .api_stack(\n",
                "        enable_rl_module_and_learner=False,\n",
                "        enable_env_runner_and_connector_v2=False,\n",
                "    )\n",
                "    .environment(\n",
                "        env=\"MiniGridFlat-v0\",\n",
                "        env_config={\"env_name\": \"BabyAI-GoToObj-v0\", \"max_steps\": 64},\n",
                "    )\n",
                "    .framework(\"torch\")\n",
                "    .env_runners(\n",
                "        num_env_runners=2,\n",
                "        num_envs_per_env_runner=4,\n",
                "    )\n",
                "    .training(\n",
                "        train_batch_size=2048,\n",
                "        sgd_minibatch_size=256,\n",
                "        lr=3e-4,\n",
                "        gamma=0.99,\n",
                "        clip_param=0.2,\n",
                "        num_sgd_iter=10,\n",
                "        entropy_coeff=0.01,\n",
                "        model={\"fcnet_hiddens\": [256, 256], \"fcnet_activation\": \"relu\"},\n",
                "    )\n",
                "    .resources(num_gpus=1 if torch.cuda.is_available() else 0)\n",
                ")\n",
                "print(\"âœ… Config created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "build"
            },
            "outputs": [],
            "source": [
                "print(\"Building PPO...\")\n",
                "algo = config.build()\n",
                "print(\"âœ… PPO built!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs('checkpoints', exist_ok=True)\n",
                "\n",
                "NUM_ITERATIONS = 200\n",
                "results = []\n",
                "\n",
                "print(f\"Training for {NUM_ITERATIONS} iterations...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for i in range(NUM_ITERATIONS):\n",
                "    result = algo.train()\n",
                "    reward = result.get(\"episode_reward_mean\", 0) or 0\n",
                "    ep_len = result.get(\"episode_len_mean\", 0) or 0\n",
                "    results.append({\"iter\": i+1, \"reward\": reward, \"len\": ep_len})\n",
                "    \n",
                "    if (i+1) % 10 == 0:\n",
                "        print(f\"Iter {i+1:3d}: reward={reward:7.3f}, len={ep_len:5.1f}\")\n",
                "    if (i+1) % 50 == 0:\n",
                "        algo.save(\"checkpoints\")\n",
                "        print(\"  ðŸ’¾ Saved\")\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"âœ… Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot"
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "rewards = [r[\"reward\"] for r in results]\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(rewards, alpha=0.5)\n",
                "if len(rewards) > 10:\n",
                "    smooth = np.convolve(rewards, np.ones(10)/10, mode='valid')\n",
                "    plt.plot(range(5, len(rewards)-4), smooth, 'r-', lw=2)\n",
                "plt.xlabel(\"Iteration\")\n",
                "plt.ylabel(\"Reward\")\n",
                "plt.title(\"Training Curve\")\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig(\"training_curve.png\")\n",
                "plt.show()\n",
                "print(f\"Final reward: {rewards[-1]:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "eval"
            },
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "from minigrid_env import MiniGridFlatEnv\n",
                "\n",
                "env = MiniGridFlatEnv({\"env_name\": \"BabyAI-GoToObj-v0\", \"max_steps\": 64})\n",
                "successes = 0\n",
                "for ep in tqdm(range(100), desc=\"Evaluating\"):\n",
                "    obs, _ = env.reset(seed=1000+ep)\n",
                "    done = False\n",
                "    while not done:\n",
                "        action = algo.compute_single_action(obs)\n",
                "        obs, reward, term, trunc, _ = env.step(action)\n",
                "        done = term or trunc\n",
                "    if term and reward > 0:\n",
                "        successes += 1\n",
                "\n",
                "print(f\"\\nðŸ“Š Success Rate: {successes}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "save"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "algo.save(\"checkpoints/final\")\n",
                "with open(\"results.json\", \"w\") as f:\n",
                "    json.dump(results, f)\n",
                "!zip -r trained_model.zip checkpoints/ results.json minigrid_env/\n",
                "print(\"ðŸ“¦ Created trained_model.zip\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "files.download('trained_model.zip')\n",
                "files.download('training_curve.png')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cleanup"
            },
            "outputs": [],
            "source": [
                "algo.stop()\n",
                "ray.shutdown()\n",
                "print(\"âœ… Done!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
